{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3GuLnmdfpJx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel, LdaModel, LsiModel\n",
        "import nltk\n",
        "from nltk import WordNetLemmatizer\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x8EpdCvd7LzN"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/drugsComTrain_raw.csv\")\n",
        "reviews=data.review.values.tolist()\n",
        "reviews=[re.sub(\"\\'\",\"\",review)for review in reviews]\n",
        "reviews=[re.sub(\"\\d+\",\"\",review)for review in reviews]\n",
        "reviews=[re.sub(\"\\#\",\"\",review)for review in reviews]\n",
        "reviews=[re.sub(\"\\&\",\"\",review)for review in reviews]\n",
        "reviews=[re.sub(\"\\;\",\"\",review)for review in reviews]\n",
        "reviews=[re.sub(\"\\%\",\"\",review)for review in reviews]\n",
        "reviews=[re.sub(\"\\(\",\"\",review)for review in reviews]\n",
        "reviews=[re.sub(\"\\)\",\"\",review)for review in reviews]\n",
        "reviews=[re.sub(\"\\@\",\"\",review)for review in reviews]\n",
        "def getwords(sentences):\n",
        "  for s in sentences:\n",
        "    yield(gensim.utils.simple_preprocess(str(s), deacc=True))\n",
        "words=list(getwords(reviews))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fKNCboVIImus"
      },
      "outputs": [],
      "source": [
        "def no_stopwords(wordds):\n",
        "  return [[word for word in simple_preprocess(str(w).lower()) if word not in stop_words] for w in wordds]\n",
        "def lemmatization(no_stop_words):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  Pos_tag = {\"J\": wordnet.ADJ,\"N\": wordnet.NOUN,\"V\": wordnet.VERB,\"R\": wordnet.ADV}\n",
        "  Le_words=[]\n",
        "  for w in no_stop_words:\n",
        "    Le_words.append(list(lemmatizer.lemmatize(word,Pos_tag.get(nltk.pos_tag([word])[0][1][0].upper(),wordnet.NOUN)) \n",
        "    for word in simple_preprocess(str(w).lower())))\n",
        "  return Le_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR-rEswXjdEf"
      },
      "outputs": [],
      "source": [
        "no_stop_words=no_stopwords(words)\n",
        "lemmatized_data=lemmatization(no_stop_words)\n",
        "lemmatized_data[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oslqzeEUmidW"
      },
      "outputs": [],
      "source": [
        "dictionary=corpora.Dictionary(lemmatized_data)\n",
        "document_term_matrix=[dictionary.doc2bow(text) for text in lemmatized_data]\n",
        "tfidf = gensim.models.TfidfModel(document_term_matrix, smartirs='ntc')\n",
        "topic_count=10\n",
        "#LSA Model using TF-IDF     \n",
        "print(\"LSA with TF-IDF: \") \n",
        "print()\n",
        "lsa_model = gensim.models.lsimodel.LsiModel(corpus=list(tfidf[document_term_matrix]),id2word=dictionary ,num_topics=15)\n",
        "for i in range(topic_count):\n",
        "  print(\"Topic:\", i,end=\" \")\n",
        "  Topic_words=lsa_model.print_topics(num_topics=10,num_words=20)[i][1].split(\"+\")\n",
        "  for j in Topic_words:\n",
        "    print(j.split(\"*\")[1],end=\" \")\n",
        "  print()\n",
        "\n",
        "#LDA Model using TF-IDF\n",
        "print()\n",
        "print(\"LDA with TF-IDF: \")\n",
        "print()\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=list(tfidf[document_term_matrix]),id2word=dictionary,\n",
        "                                            num_topics=topic_count,random_state=100,chunksize=1000,passes=10)\n",
        "for i in range(topic_count):\n",
        "  print(\"Topic:\", i,end=\" \")\n",
        "  Topic_words=lda_model.print_topics(num_topics=10,num_words=20)[i][1].split(\"+\")\n",
        "  for j in Topic_words:\n",
        "    print(j.split(\"*\")[1],end=\" \")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bem_1aoZxb4X"
      },
      "outputs": [],
      "source": [
        "#LSA Model using (Bag Of Words) Document term matrix     \n",
        "print(\"LSA with Bag of Words: \") \n",
        "print()\n",
        "lsa_model_doc = gensim.models.lsimodel.LsiModel(corpus=document_term_matrix,id2word=dictionary ,num_topics=13)\n",
        "print()\n",
        "for i in range(topic_count):\n",
        "  print(\"Topic:\",i,end=\" \")\n",
        "  Topic_words=lsa_model_doc.print_topics(num_topics=10,num_words=20)[i][1].split(\"+\") \n",
        "  for j in Topic_words:\n",
        "    print(j.split(\"*\")[1],end=\" \")\n",
        "  print()\n",
        "#LDA Model using (Bag Of Words) Document term matrix\n",
        "print()\n",
        "print()\n",
        "print(\"LDA with Bag of Words: \")\n",
        "print()\n",
        "lda_model_doc = gensim.models.ldamodel.LdaModel(corpus=document_term_matrix,id2word=dictionary,num_topics=15,\n",
        "                                                random_state=100,chunksize=1000,passes=10)\n",
        "for i in range(topic_count):\n",
        "  print(\"Topic:\",i,end=\" \")\n",
        "  Topic_words=lsa_model_doc.print_topics(num_topics=10,num_words=20)[i][1].split(\"+\")\n",
        "  for j in Topic_words:\n",
        "    print(j.split(\"*\")[1],end=\" \")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAD4_GxU59nZ"
      },
      "outputs": [],
      "source": [
        "# Compute Perplexity\n",
        "print('\\n TF-IDF Perplexity: ', lda_model.log_perplexity(list(tfidf[document_term_matrix])))  # a measure of how good the model is. lower the better.\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=lemmatized_data, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\n TF-IDF Coherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PA4qKYSZhImW"
      },
      "outputs": [],
      "source": [
        "# Compute Perplexity\n",
        "print('\\n Document Perplexity: ', lda_model_doc.log_perplexity(document_term_matrix))  # a measure of how good the model is. lower the better.\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model_doc, texts=lemmatized_data, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\n Document Coherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XHmoJG1i0ys5"
      },
      "outputs": [],
      "source": [
        "# Coherence Function\n",
        "def coherence_function(name,corpus,low,high,dictionary,data):\n",
        "  print(name)\n",
        "  coherence_values = []\n",
        "  models = []\n",
        "  for num_topics in range(low,high+1):\n",
        "    if name[0:3]==\"LDA\":\n",
        "      model = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=dictionary,num_topics=num_topics)\n",
        "    else:\n",
        "      model = gensim.models.lsimodel.LsiModel(corpus=corpus,id2word=dictionary ,num_topics=topic_count)\n",
        "    models.append(model)\n",
        "    coherencemodel = CoherenceModel(model=model, texts=data, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_values.append(coherencemodel.get_coherence())\n",
        "    print(\"Topics:\", num_topics, \"Coherence: \",coherence_values[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGC07Vd4nzp2"
      },
      "outputs": [],
      "source": [
        "coherence_function(\"LSA_TF-IDF\",list(tfidf[document_term_matrix]),1,20,dictionary,lemmatized_data)\n",
        "print(\"-----------------------------------------------------------------------------------------\")\n",
        "coherence_function(\"LDA_TF-IDF\",list(tfidf[document_term_matrix]),1,20,dictionary,lemmatized_data)\n",
        "print(\"-----------------------------------------------------------------------------------------\")\n",
        "coherence_function(\"LSA_BOW\",document_term_matrix,1,20,dictionary,lemmatized_data)\n",
        "print(\"-----------------------------------------------------------------------------------------\")\n",
        "coherence_function(\"LDA_BOW\",document_term_matrix,1,20,dictionary,lemmatized_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}